\section{Variations in presentation}

\subsection{A little history}
Haskell was the first programming language to popularize the notion of
monad as a structuring technique for functional programming. There
were several key ideas that went into the $\Haskell$ packaging of the
idea. One was to treat the core elements that make up a monad more or
less \emph{directly} without appeal to category theory -- the branch
of mathematics where the notion originated. This is considerably
easier to do in a functional programming language because the ambient
language can be thought of as a category; thus, for the average
programmer there is no need to refer to categories, in general, but
only to the ``universe'' of programs that can be written in the
language at hand. Then, because Haskell already has a notion of
parametric polymorphism, a monad's most central piece of data is a
parametric type constructor, say $T$.

\paragraph{Haskell's monad API}
Given such a type constructor, you only need a pair of maps (one of
which is higher order). Thus, in $\Haskell$ a monad is presented in
terms of the following data

\begin{itemize}
  \item a parametric type constructor, \lstinline[language=Haskell]!T! a
  \item a \lstinline[language=Haskell]!return! map enjoying the
    signature \lstinline[language=Haskell]!return :: a -> T a!
  \item a \lstinline[language=Haskell]!bind! map enjoying the
    signature \lstinline[language=Haskell]!bind : T a -> (a -> T b) -> T b!
\end{itemize}

In $\Haskell$ these elements can be collected inside a
\lstinline[language=Haskell]!typeclass!. Resulting in a declaration of
the form

% TODO : add typeclass
\begin{lstlisting}[captionpos=b,language=Haskell,caption=monad typeclass]
  typeclass Monad T a where
   return :: a -> T a
   bind :: T a -> (a -> T b ) -> T b
\end{lstlisting}

Now, it's not enough to simply have this collection of pieces. The
pieces have to fit together in a certain way; that is, they are
subject to the following laws:

\begin{itemize}
  \item \lstinline[language=Haskell]!return (bind a f)! $\equiv$ \lstinline[language=Haskell]!f a! %[Left identity]
  \item \lstinline[language=Haskell]!bind m return! $\equiv$ \lstinline[language=Haskell]!m! %[Right identity]
  \item \lstinline[language=Haskell]!bind (bind m f) g! $\equiv$ \lstinline[language=Haskell]!bind m (\ x -> bind (f x) g)! %[Associativity]
\end{itemize}

\paragraph{Do-notation}
One of the driving motivations for this particular formulation of the
concept is that it makes it very easy to host a little DSL inside the
language. The syntax and semantics of the DSL is simultaneously given
by the following procedure for de-sugaring, i.e. translating
expressions in the DSL back to core \texttt{Haskell}.

\begin{lstlisting}[language=Haskell,mathescape=true]
do { x } $=$ x
 
do { x ; <stmts> }
  $=$ bind x (\_ -> do { <stmts> })
 
do { v <- x ; <stmts> }
  $=$ bind x (\v -> do { <stmts> }) 

do { let <decls> ; <stmts> }
  $=$ let <decls> in do { <stmts> }
\end{lstlisting} 

The assignment-like operation extends to full pattern matching with

\begin{lstlisting}[language=Haskell,mathescape=true]
  do { p <- x ; <stmts> }
  $=$ let f p = do { <stmts> }
              f _     = fail "..."
      in bind x f
\end{lstlisting}

On the face of it, the notation provides both a syntax and a semantics
reminiscent of the standard side-effecting operations of mainstream
imperative languages. In presence of polymorphism, however, these
instruments are much more powerful. These operations can be
\emph{systematically} ``overloaded'' (meaning the overloaded
definitions satisfy the laws above). This allows to systematically use
the notation for a wide variety of computations that all have some
underlying commonality. Typical examples include I/O, state
management, control flow (all three of which all bundle up in
parsing), and also container navigation and manipulation. It gets
better for many of the tools of mathematics that are regularly the
subject of computer programs such probability distributions,
integration, etc., also have presentations as monads. Thus, innocent
examples like this one

\begin{lstlisting}[language=Haskell]
  do { putStrLn "Enter a line of text:";
       x <- getLine;
       putStrLn ("you wrote: " ++ x) }
\end{lstlisting}

as might be found in some on-line tutorial on monads belie the potency
of this combination of ideas.

\paragraph{for-comprehensions}
Unlike $\Haskell$, $\Scala$ does not reify the notion of monad under a
\lstinline[language=Scala]!trait!, the language's equivalent of
$\Haskell$'s \lstinline[language=Haskell]!typeclass!. Instead the
systematic means of de-sugaring
\lstinline[language=Scala]!for!-notation and polymorphic
interpretations of \lstinline[language=Scala]!flatMap!, etc are the
effective definitions of the notion in $\Scala$.

The basic \texttt{Scala} construct looks like

\begin{lstlisting}[language=Scala]
  for( p <- e [; p <- e] [p = e] [if t] ) yield { e }
\end{lstlisting}

and the de-sugaring looks like

\begin{lstlisting}[language=Scala,mathescape=true]
  for( x <- expr$_1$ ; y <- expr$_2$ ; <stmts> ) yield expr$_3$

  $=$

  expr$_1$ flatMap( x => for( y <- expr$_2$; <stmts> ) yield expr$_3$ )

  for( x <- expr$_1$ ; y = expr$_2$ ; <stmts> ) yield expr$_3$
  
  $=$

  for( ( x, y ) <- for ( x <- expr$_1$ ) yield ( x, expr$_2$ ); <stmts> )
  yield expr$_3$

  for( x <- expr$_1$ if pred ) yield expr$_2$ 

  $=$

  expr$_1$ filter ( x => pred ) map ( x => expr$_2$ )    
\end{lstlisting}

Again, general pattern matching is supported in assignment-like statements.

\begin{lstlisting}[language=Scala,mathescape=true]
  for( p <- expr$_1$ ; <stmts> ) yield expr$_2$ 

  $=$

  expr$_1$ filter {
    case p => true
    case _ => false
  } flatMap {
    p => for( <stmts> ) yield expr$_2$
  }
\end{lstlisting}

This means, therefore, that we have the following correspondence

% TODO write down the $\Haskell$/$\Scala$ monad correspondence

\subsection{A little more history}

If one were to reify the notion in $\Scala$ there are several design
choices -- all of which endure some desiderata. Following the original
presentation developed in category theory, however, has some crucial
advantages:

\begin{itemize}
  \item intuition
  \item correspondence to previously existing structures
  \item decomposition of the requirements 
\end{itemize}

which we explore in some detail here.

\subsubsection{Intuition: Monad as container}

As we will see the notion of monad maps nicely onto an appropriately
parametric notion of container. From this point of view we can imagine
a container ``API'' that has three basic operations. 
\paragraph{Shape of the container} The first of these is a
\emph{parametric} specification of the \emph{shape} of the
container. Examples of container shapes include: \lstinline[language=Scala]!List[A]!,
\lstinline[language=Scala]!Set[A]!, \lstinline[language=Scala]!Tree[A]!, etc. At the outset we remain
uncommitted to the particular shape. The API just demands that
there is some shape, say \lstinline[language=Scala]!S[A]!.
\paragraph{Putting things into the container} The next operation is
very basic, it says how to put things into the container. To align
with a very long history, we will refer to this operation by the name
\lstinline[language=Scala]!unit!. Since the operation is supposed to allow us to put
elements of type \lstinline[language=Scala]!A! into containers of shape \lstinline[language=Scala]!S[A]!, we
expect the signature of this operation to be \lstinline[language=Scala]!unit : A => S[A]!.
\paragraph{Flattening nested containers} Finally, we want a generic
way to flatten nested containers. Just like there's something
fundamentally the same about the obvious way to flatten nested lists
and nested sets, we ask that the container API provide a canonical way
to flatten nested containers. If you think about it for a moment, if a
container is of shape, \lstinline[language=Scala]!S[A]!, then a nested container will be
of shape, \lstinline[language=Scala]!S[S[A]]!. If history demands that we call our
flattening operation \lstinline[language=Scala]!mult!, then our generic flatten operation
will have signature, \lstinline[language=Scala]!mult : S[S[A]] => S[A]!.

\subsubsection{Preserving connection to existing structure: Monad as
  generalization of monoid}

Programmers are very aware of data structures that support a kind of
concatenation operation. The data type of \lstinline[language=Scala]!String! is a perfect
example. Every programmer expects that the concatenation of a given
\lstinline[language=Scala]!String!, say \lstinline[language=Scala]!s!, with the empty \lstinline[language=Scala]!String!,
\lstinline[language=Scala]!""! will return a result string equal to the original. In
code, \lstinline[language=Scala]! s.equals( s + "" ) == true !. Likewise, string
concatenation is insensitive to the order of operation. Again, in
code, \lstinline[language=Scala]! (( s + t ) + u).equals( s + ( t + u ) ) == true !.

Most programmers have noticed that these very same laws survive
polymorphic interpretations of \lstinline[language=Scala]!+!, \lstinline[language=Scala]!equals! and the
``empty'' element. For example, if we substituted the data type
\lstinline[language=Scala]!Integer! as the base type and used integer addition, integer
equality, and \lstinline[language=Scala]!0! as the empty element, these same code
snippets (amounting assertions) would still work.

Many programmers are aware that there is a very generic underlying
data type, historically referred to as a \emph{monoid} defined by
these operations and laws. In code, we can imagine defining a
\lstinline[language=Scala]!trait! in $\Scala$ something like

\begin{lstlisting}[language=Scala]
  trait Monoid {
    def unit : Monoid
    def mult( that : Monoid ) 
  }
\end{lstlisting}

This might allow \emph{views} of \lstinline[language=Scala]!Int! as a monoid as in

\begin{lstlisting}[language=Scala]
  class MMultInt extends Int with Monoid {
    override def unit = 1
    override def mult( that : Monoid ) = this * that
    }
\end{lstlisting}

except for the small problem that \lstinline[language=Scala]!Int! is
\lstinline[language=Scala]!final! (illustrating an important
difference between the adhoc polymorphism of \texttt{Haskell}'s
\lstinline[language=Haskell]!typeclass! and \texttt{Scala}'s
\lstinline[language=Scala]!trait!).

Any solution will depend on type parametrization. For example

\begin{lstlisting}[language=Scala]
  trait Monoid[Element] {
    def unit : Element
    def mult( a : Element, b : Element ) 
  }
\end{lstlisting}

and corresponding view of \lstinline[language=Scala]!Int! as a monoid.

\begin{lstlisting}[language=Scala]
  class MMultInt extends Monoid[Int] {
    override def unit : Int = 1
    override def mult( a : Int , b : Int ) = a * b
  }
\end{lstlisting}

This parametric way of viewing some underlying data structure is
natural both to the modern programmer and the modern
mathematician. Both are quite familiar with and make extensive use of
overloading of this kind. Both are very happy to find higher levels of
abstraction that allow them to remain DRY when the programming demands
might cause some perspiration. One of the obvious places where
repetition is happening is in the construction of view. Consider
another view of \lstinline[language=Scala]!Int!

\begin{lstlisting}[language=Scala]
  class MAddInt extends Monoid[Int] {
    override def unit : Int = 0
    override def mult( a : Int , b : Int ) = a + b
  }
\end{lstlisting}

It turns out that there is a lot of machinery that is common to
defining a view like this for any given data type. Category theorists
realized this and recognized that you could reify the \emph{view}
which not only provides a place to refactor the common machinery, but
also to give it another level of polymorphism. Thus, a category
theorist's view of the monad API might look something like this.

\begin{lstlisting}[language=Scala]
  trait Monad[Element,M[_]] {
    def unit( e : Element ) : M[Element]
    def mult( mme : M[M[Element]] ) : M[Element] 
  }
\end{lstlisting}

The family resemblance to the \lstinline[language=Scala]!Monoid! API
is not accidental. The trick is to bring syntax back into the picture. Here's an example.

\begin{lstlisting}[language=Scala]
  case class MonoidExpr[Element]( val e : List[Element] )
  class MMInt extends Monad[Int,MonoidExpr] {
    override def unit( e : Int ) = MonoidExpr( List( e ) )
    override def mult( mme : MonoidExpr[MonoidExpr[Int]] ) =
    mme match {
      case MonoidExpr( Nil ) =>
         MonoidExpr( Nil )
      case MonoidExpr( mes ) => 
         MonoidExpr(
            ( Nil /: mes)( 
               { ( acc, me ) => me match { 
                   case MonoidExpr( es ) => acc +++ es 
                 } 
               } 
             )
         )
    }
  }
\end{lstlisting}

While it's clear that \lstinline[language=Scala]!unit! turns
\lstinline[language=Scala]!Int!s into integer expressions, what the
operation \lstinline[language=Scala]!mult! is doing is canonically
flattening nested expressions in a way the exactly parallels the
flattening of nest arithmetic addition expressions. For a broad class
of monads, this is the paradigmatic behavior of
\lstinline[language=Scala]!mult!. The fact that monads are
characterized by a generic interpretation of flattening of nested
structure, by the way, makes the choice of the term
\lstinline[language=Scala]!flatMap! particularly appropriate.

\paragraph{Associativity as flattening}
Looking at it from the other way around, one of the properties of a
monoid is that it's binary operation, it's
\lstinline[language=Scala]!mult! is associative. The actual content of
the notion of associativity is that order of grouping doesn't make any
difference. In symbols, a binary operation, $*$, is associative when
$a*(b*c) = (a*b)*c$. This fact gives us the right to erase the parens
and simply write $a*b*c$. In other words, associativity is
flattening. A similar connection can be made for
\lstinline[language=Scala]!unit! and the identity of a monoid. One
quick and dirty way to see this is that since we know that $a*e=a$
(when $e$ is the unit of the monoid) then the expression $a*e$
effectively nests $a$ in a
\lstinline[language=Scala]!MonoidExpr!. That's the ``moral'' content
of the connection between the two notions of unit.

\paragraph{Syntax and containers}
The crucial point in all of this is that \emph{syntax is the only
  container we have for computation}. What do we mean by this? Back
when Moggi was crafting his story about the application of the notion
of monad to computing he referred to monads as ``notions of
computation''. What he meant by that was that monads reify computation
(such as I/O or flow of control or constructing data structures) into
``objects''. Computation as a phenomenon, however, is both dynamic and
(potentially) infinitary. At least as we understand it today, it's not
in the category of widgets we can hold in our hand like an apple or an
Apple $\texttrademark$ computer. All we can do is \emph{point} to it,
indicate it in some way. Syntax, it turns out, is our primary means of
signifying computation. 

\paragraph{Bracing for \texttt{XML}}
In this connection it is useful to make yet another connection to a
ubiquitous technology, namely \texttt{XML}. As a segue, notice that we
can always write a binary operation in prefix notation as well as
infix. That is, whatever we could write at $a*b$ we could just as
easily write as $*(a,b)$. The flattening property of associativity
says we can drop nesting such as $*(a,*(b,c))$ in favor of
$*(a,b,c)$. In this sense, the syntax of braces is a kind of generic
syntax for monoids and monads. If we introduce the notion of
``colored'' braces, this becomes even more clear at the lexicographic
or notational level. So, instead of $*(a,b,c)$ we'll mark the
``color'' of the braces like so: $(*| ... |*)$, where $*$ can be any
color. Then, at the level of monoid the unit is the empty braces, $(*|
|*)$, while at the level of the monad the unit places the element, say
$a$, in between the braces: $(*| a |*)$. The conceptual connection
between the two variations of the operation now becomes clear: writing
$a*e$ is the same as writing $*(a,e)$ which is the same as writing
$(*| a , (*| |*) |*)$, which canonically flattens into $(*| a |*)$.

Now, anyone who's spent any time around \texttt{XML} can see where
this is headed. At a purely syntactic, lexicographic level we replace
round brackets with angle brackets and we have exactly \texttt{XML}
notation for elements. In this sense, \texttt{XML} is a kind of
universal notation for monads. The only thing missing from the
framework is a means to associate operations to unit and mult, i.e. to
inserting content into elements and flattening nested
elements. \texttt{Scala}'s specific support for \texttt{XML} puts it
in an interesting position to rectify this situation.

\paragraph{The connection with set-comprehensions}
Finally, since we've gone this far into it, we might as well make the
connection to comprehensions. Again, let's let notation support our
intuitions. The above discussion should make it clear that its not the
particular shape of the brace that matters, but the action of
``embracing'' a collection of elements that lies at the heart of the
notion. So, it's fine if we shift to curly braces to be
suggestive. Thus, we are looking at a formalism that allows us to
polymorphically ``collect'' elements between braces, like $\{*| a, b, c |*\}$.

This is fine for finite collections, but what about infinitary
collections or coollections of elements selected programmatically,
rather than given explicitly. The set theoretic notation was designed
specifically for this purpose. When we have an extant set of elements
that we can give explicitly, we simply write $\{ a_1, a_2, a_3, ... \}$.

When we have a potentially infinitary collection of elements, or
elements that are selected on the basis of a condition, then we write
$\{ pattern \in S | condition \}$. The idea of monad as comprehension
recognizes that these operations of collecting, pattern matching and
selection on the basis of a condition can be made \emph{polymorphic}
using monads. Notationally, we can denote the different polymorphic
interpretations by the ``color'' of the brace. In other words, we are
looking at a shift of the form
\begin{itemize}
  \item $\{ a_1, a_2, a_3, ... \} \mapsto \{*| a_1, a_2, a_3, ... |*\}$
  \item $\{ pattern \; \in \; S \;|\; condition |\} \mapsto \{*| pattern \in S \; | \; condition |*\}$
\end{itemize}
to build into our notation an explicit representation of the fact that
the operation of collection, pattern matching and filtering on the
basis of predicate are polymorphic.

Often times, good mathematics, like good programmings is really about
the design of good notation -- it's about DSLs! In this case, the
notation is particularly useful because it begs the question of the
language of patterns and the language of conditions -- something that
Wadler's original paper on monads as generalized comprehensions did
not address. This is a theme to which we will return at the end of the
book. For now, the central point is to understand how monad as
container and monad as generalization of monoid are actually views of
the same underlying idea.

\subsubsection{Decomposition of monad requirements}

The constraints on any given monad candidate are well factored into
three different kinds of requirements -- operating at different levels
of the ``API'': functoriality, naturality and coherence. Often these
can be mechanically verified, and when they can't there are natural
ways to generate spot-checks that fit well with tools such as
$\ScalaCheck$.

\subsubsection{A categorical way to look at monads}

In category theory the monad is presented in terms of the
following data

\begin{itemize}
  \item a ``unit'' map enjoying the signature $unit : A \to T[A]$
  \item a ``mult'' map enjoying the signature $mult : T[T[A]] \to T[A]$
\end{itemize}

subject to the following laws:

\begin{itemize}
  \item $T( id_A ) = id_{T[A]}$ %[Functoriality]
  \item %[Naturality]
    \begin{itemize}
    \item $unit(f) \circ unit_{A} = unit_{B} \circ unit(B)$ %[unit]
    \item $mult(f) \circ mult_{T[A]} = mult_{T[B]} \circ mult(B)$ %[mult]
    \end{itemize}
  \item %[Coherence]
    \begin{itemize}
    \item $mult \circ T mult = mult \circ mult T$ %[mult-mult]
    \item $mult \circ T unit = mult \circ unit T$ %[mult-unit]
    \end{itemize}
\end{itemize}

These two definitions are interchangeable. That's what makes them
``presentations'' of the same underlying idea.

One of the reasons for the difference in presentation is that $\Haskell$
doesn't treat the Monad type class as a Functor. The refactoring of
the $mult$ map into the $bind$ map is that it builds functoriality
into definition. The other reason is the do notation.




